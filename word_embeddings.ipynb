{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.array(list(map(float, tokens[1:])))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embd = load_vectors('data/wiki.en.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecQ1 = np.zeros((3, 300), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecQ1[0,:] = embd['far']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18551  ,  0.015872 , -0.039883 ,  0.18648  ,  0.043087 ,\n",
       "        0.18006  ,  0.1393   , -0.053945 , -0.064611 ,  0.21688  ,\n",
       "       -0.018256 , -0.080848 , -0.23366  , -0.27057  ,  0.084884 ,\n",
       "       -0.21269  , -0.071294 ,  0.11778  ,  0.046965 ,  0.018339 ,\n",
       "        0.085179 , -0.023397 , -0.15475  , -0.24089  , -0.062164 ,\n",
       "       -0.087426 ,  0.2149   ,  0.015881 , -0.016373 ,  0.13569  ,\n",
       "       -0.039262 ,  0.41436  , -0.43571  ,  0.4263   ,  0.087347 ,\n",
       "       -0.18151  ,  0.025339 , -0.15018  , -0.23302  , -0.19211  ,\n",
       "        0.03098  , -0.014375 , -0.044042 , -0.083952 , -0.050248 ,\n",
       "        0.22082  ,  0.012041 , -0.12963  ,  0.076374 , -0.33944  ,\n",
       "       -0.13269  , -0.21237  , -0.010519 , -0.10086  , -0.23662  ,\n",
       "       -0.035792 , -0.21752  ,  0.21943  , -0.25363  ,  0.29082  ,\n",
       "       -0.44182  , -0.046488 ,  0.12439  ,  0.010365 , -0.19277  ,\n",
       "        0.074712 , -0.17948  ,  0.12401  ,  0.055139 ,  0.085494 ,\n",
       "       -0.036012 , -0.0068908,  0.0022525, -0.24754  , -0.18684  ,\n",
       "        0.088908 ,  0.026108 ,  0.34949  , -0.1562   , -0.30075  ,\n",
       "        0.16121  , -0.13569  , -0.012885 ,  0.018955 , -0.035906 ,\n",
       "        0.01964  , -0.24644  ,  0.085061 , -0.086709 ,  0.11511  ,\n",
       "       -0.22987  ,  0.002314 ,  0.40162  , -0.059604 , -0.19691  ,\n",
       "       -0.22718  ,  0.28374  , -0.085116 , -0.059286 ,  0.14447  ,\n",
       "       -0.063157 , -0.22867  ,  0.12971  , -0.37239  , -0.036479 ,\n",
       "       -0.044713 , -0.061809 ,  0.021678 , -0.072655 ,  0.23313  ,\n",
       "       -0.092435 ,  0.1437   , -0.1574   ,  0.12743  ,  0.098142 ,\n",
       "       -0.076783 ,  0.18749  ,  0.13666  , -0.026911 , -0.03366  ,\n",
       "        0.13871  ,  0.08799  ,  0.0478   ,  0.44933  ,  0.17947  ,\n",
       "        0.075818 ,  0.11463  , -0.062458 ,  0.097157 , -0.33902  ,\n",
       "        0.049452 ,  0.092233 , -0.14905  ,  0.067149 , -0.16679  ,\n",
       "       -0.038198 ,  0.074082 ,  0.11639  , -0.0093549,  0.28475  ,\n",
       "       -0.14369  ,  0.078561 ,  0.20699  ,  0.012734 , -0.0534   ,\n",
       "        0.098186 , -0.047433 ,  0.027842 ,  0.29542  ,  0.042021 ,\n",
       "        0.049195 , -0.27377  ,  0.012406 ,  0.075566 , -0.23549  ,\n",
       "       -0.27087  ,  0.10617  ,  0.072853 ,  0.031723 ,  0.31055  ,\n",
       "       -0.060263 ,  0.3639   , -0.13759  ,  0.0022362,  0.057134 ,\n",
       "       -0.10096  , -0.15335  , -0.17874  ,  0.31782  ,  0.20689  ,\n",
       "       -0.22591  , -0.22412  , -0.2054   , -0.2349   , -0.26339  ,\n",
       "        0.19397  ,  0.15504  ,  0.033932 ,  0.14347  , -0.16399  ,\n",
       "        0.15643  ,  0.001708 ,  0.24388  ,  0.1741   ,  0.015269 ,\n",
       "        0.10113  , -0.1167   , -0.24357  ,  0.22614  , -0.17459  ,\n",
       "        0.091568 , -0.41041  , -0.16269  ,  0.045576 ,  0.07692  ,\n",
       "        0.10645  ,  0.005121 ,  0.21515  , -0.25632  , -0.31001  ,\n",
       "       -0.18638  , -0.12336  , -0.061039 ,  0.28771  , -0.21861  ,\n",
       "       -0.0023317, -0.061928 ,  0.18813  , -0.11827  ,  0.19952  ,\n",
       "        0.49636  , -0.19485  , -0.19428  , -0.16201  , -0.13314  ,\n",
       "       -0.20999  ,  0.01009  , -0.17832  , -0.21694  ,  0.12943  ,\n",
       "        0.11094  ,  0.080292 , -0.19681  , -0.11285  ,  0.16003  ,\n",
       "       -0.1089   , -0.01346  , -0.13595  , -0.13907  , -0.011788 ,\n",
       "       -0.045468 ,  0.45979  ,  0.31247  , -0.098891 , -0.14286  ,\n",
       "        0.23522  , -0.0081504,  0.01233  , -0.20292  ,  0.1679   ,\n",
       "       -0.019653 , -0.13999  ,  0.13582  ,  0.14866  , -0.1344   ,\n",
       "       -0.066918 ,  0.15961  ,  0.052594 ,  0.20834  ,  0.20818  ,\n",
       "       -0.080159 , -0.070236 , -0.090403 ,  0.053315 ,  0.05006  ,\n",
       "        0.076117 , -0.090257 , -0.094624 ,  0.12959  ,  0.287    ,\n",
       "        0.028787 ,  0.076472 , -0.026689 , -0.30004  , -0.10899  ,\n",
       "       -0.39607  , -0.082531 ,  0.2763   , -0.24138  , -0.14996  ,\n",
       "       -0.19605  ,  0.084265 ,  0.2416   ,  0.11262  ,  0.12344  ,\n",
       "       -0.098624 ,  0.017279 ,  0.30019  ,  0.23099  , -0.24155  ,\n",
       "        0.4613   , -0.027995 , -0.25526  ,  0.027209 , -0.025009 ,\n",
       "       -0.16521  , -0.068007 , -0.26846  ,  0.14215  ,  0.25742  ,\n",
       "        0.13663  ,  0.16385  , -0.12599  ,  0.26738  ,  0.068315 ,\n",
       "       -0.13004  ,  0.0027769, -0.012117 ,  0.14798  ,  0.14471  ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embd['far']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bin'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'wiki.en.bin'.split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe750126310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.5667, -1.4303,  0.5009,  0.5438, -0.4057],\n",
      "        [ 1.1341, -1.1115,  0.3501, -0.7703, -0.1473],\n",
      "        [-2.5667, -1.4303,  0.5009,  0.5438, -0.4057],\n",
      "        [ 1.1341, -1.1115,  0.3501, -0.7703, -0.1473],\n",
      "        [ 1.1341, -1.1115,  0.3501, -0.7703, -0.1473],\n",
      "        [ 1.1341, -1.1115,  0.3501, -0.7703, -0.1473]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "embeds = nn.Embedding(2, 5)  # 2 words in vocab, 5 dimensional embeddings\n",
    "lookup_tensor = torch.tensor([0,1,0,1,1,1], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.1341, -1.1115,  0.3501, -0.7703, -0.1473]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "for i in embeds.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6984, -0.8005],\n",
       "        [ 1.5381,  1.4673],\n",
       "        [ 1.5951, -1.5279]], requires_grad=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "a = Variable(torch.randn(3,2), requires_grad=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(3,2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0,0,].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,3,4)\n",
    "b = torch.randn(1,4,3)\n",
    "torch.matmul(a, b).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.repeat(1,2,1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8803,  0.5456],\n",
       "         [-0.5979,  0.3257],\n",
       "         [-0.5642, -1.1759]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1, 3, 2) # [B, T, D]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.8803,  0.5456],\n",
       "          [ 0.8803,  0.5456],\n",
       "          [ 0.8803,  0.5456]],\n",
       "\n",
       "         [[-0.5979,  0.3257],\n",
       "          [-0.5979,  0.3257],\n",
       "          [-0.5979,  0.3257]],\n",
       "\n",
       "         [[-0.5642, -1.1759],\n",
       "          [-0.5642, -1.1759],\n",
       "          [-0.5642, -1.1759]]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.repeat(1, 1, 3).view(1, 3, 3, 2) # [B, T, T, D]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.5083,  0.1054],\n",
       "          [-1.6050, -0.1064],\n",
       "          [ 0.2466,  0.6125],\n",
       "          [-0.0077,  2.6158]],\n",
       "\n",
       "         [[ 1.0757, -0.5536],\n",
       "          [-1.6160,  0.0934],\n",
       "          [-1.3898, -0.3105],\n",
       "          [ 1.0693,  1.4394]],\n",
       "\n",
       "         [[ 1.3694,  0.4539],\n",
       "          [-0.0498,  0.3745],\n",
       "          [ 1.4389,  1.4151],\n",
       "          [-0.1589, -0.7360]]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.randn(1, 3, 4, 2) # [B, T, T2, D]\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3853, -1.4709,  0.5513,  1.4205],\n",
       "         [-0.8234,  0.9966,  0.7298, -0.1705],\n",
       "         [-1.3064, -0.4123, -2.4758,  0.9552]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.diagonal( a.matmul(h.transpose(-2, -1)), dim1=1, dim2=2 ).transpose(-2, -1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.size() # [B, T, T2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = torch.randn(2, 5, 5)\n",
    "torch.diagonal(D, dim1=1, dim2=2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
