{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torchnlp.datasets import snli_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = snli_dataset(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = snli_dataset(dev=True)\n",
    "test_data = snli_dataset(test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "def prepare_dataset(dataset):\n",
    "    \n",
    "    stats = {}\n",
    "    count_E = 0\n",
    "    count_C = 0\n",
    "    count_N = 0\n",
    "    l_E = {'premise':[], 'hypothesis':[]}\n",
    "    l_C = {'premise':[], 'hypothesis':[]}\n",
    "    l_N = {'premise':[], 'hypothesis':[]}\n",
    "    \n",
    "    for t in dataset:\n",
    "        \n",
    "        premise = t['premise']\n",
    "        hypothesis = t['hypothesis']\n",
    "        premise_tokens = nltk.word_tokenize(premise)\n",
    "        hypothesis_tokens = nltk.word_tokenize(hypothesis)\n",
    "        \n",
    "        t['premise_tokens'] = premise_tokens\n",
    "        t['hypothesis_tokens'] = hypothesis_tokens\n",
    "        \n",
    "        if t['label'] == 'neutral':\n",
    "            count_N += 1\n",
    "            l_N['premise'].append(len(premise_tokens))\n",
    "            l_N['hypothesis'].append(len(hypothesis_tokens))\n",
    "        elif t['label'] == 'contradiction':\n",
    "            count_C += 1\n",
    "            l_C['premise'].append(len(premise_tokens))\n",
    "            l_C['hypothesis'].append(len(hypothesis_tokens))\n",
    "        else:\n",
    "            count_E += 1\n",
    "            l_E['premise'].append(len(premise_tokens))\n",
    "            l_E['hypothesis'].append(len(hypothesis_tokens))\n",
    "        \n",
    "        del t['premise_transitions'], t['hypothesis_transitions']\n",
    "        \n",
    "    return count_E, count_C, count_N, l_E, l_C, l_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_e, tr_c, tr_n, tr_le, tr_lc, tr_ln = prepare_dataset(train_data)\n",
    "dev_e, dev_c, dev_n, dev_le, dev_lc, dev_ln = prepare_dataset(dev_data)\n",
    "test_e, test_c, test_n, test_le, test_lc, test_ln = prepare_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'train': list(train_data), 'dev': list(dev_data), 'test': list(test_data), \n",
    "        'n_entail': {'train': tr_e, 'dev':dev_e, 'test':test_e},\n",
    "        'n_contradiction': {'train':tr_c, 'dev':dev_c, 'test':test_c}, \n",
    "        'n_neutral': {'train':tr_n, 'dev':dev_n, 'test':test_n}, \n",
    "        'split_size': {'train':tr_e + tr_c + tr_n, 'dev':dev_e+dev_c+dev_n, 'test':test_e+test_c+test_n}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "with open(os.path.join('data', 'snli_data.json'), 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 184201, 'dev': 3487, 'test': 3544}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['n_entail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 183187, 'dev': 3278, 'test': 3237}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['n_contradiction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 182764, 'dev': 3235, 'test': 3219}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['n_neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'Children smiling and waving at camera',\n",
       " 'hypothesis': 'There are children present',\n",
       " 'label': 'entailment',\n",
       " 'premise_tokens': ['Children', 'smiling', 'and', 'waving', 'at', 'camera'],\n",
       " 'hypothesis_tokens': ['There', 'are', 'children', 'present']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastText'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e101e3385f27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimeSince\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdump_to_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreload_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_json_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/KNLI/misc/utilities.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mntpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfastText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mPreload_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastText'"
     ]
    }
   ],
   "source": [
    "from misc.utilities import timeSince, dump_to_json, create_dir, Preload_embedding, read_json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa, bb = torch.max(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
